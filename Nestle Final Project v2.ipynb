{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "E5vJOngiYdi7",
   "metadata": {
    "id": "E5vJOngiYdi7"
   },
   "source": [
    "# **Conversational Chatbot for NESTLE HR using Gradio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2357726b",
   "metadata": {
    "id": "2357726b"
   },
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import os\n",
    "import openai\n",
    "import sys\n",
    "import gradio as gr\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "431b5328",
   "metadata": {
    "id": "431b5328"
   },
   "outputs": [],
   "source": [
    "#Using PyPDF\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "Doc_loader = PyPDFLoader(\"NESTLE_HR_POLICY_2012.pdf\")\n",
    "extracted_text = Doc_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "997c60d0",
   "metadata": {
    "id": "997c60d0"
   },
   "outputs": [],
   "source": [
    "# Text splitting\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter  = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=150,\n",
    "    chunk_overlap=0,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \"(?<=\\. )\", \" \", \"\"]\n",
    ")\n",
    "splitted_text=text_splitter.split_documents(extracted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a0bae9d",
   "metadata": {
    "id": "0a0bae9d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225/2304085244.py:3: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embeddings = OpenAIEmbeddings()\n"
     ]
    }
   ],
   "source": [
    "# Embeddings\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5a3ce63",
   "metadata": {
    "id": "b5a3ce63"
   },
   "outputs": [],
   "source": [
    "# Vector store\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b380f97",
   "metadata": {
    "id": "5b380f97"
   },
   "outputs": [],
   "source": [
    "vectordb = FAISS.from_documents(\n",
    "    documents=splitted_text,\n",
    "    embedding=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9222db36",
   "metadata": {
    "id": "9222db36"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225/3107502072.py:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
     ]
    }
   ],
   "source": [
    "# LLM\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95613f21",
   "metadata": {
    "id": "95613f21"
   },
   "outputs": [],
   "source": [
    "# Retrieval chain\n",
    "from langchain.chains import RetrievalQA\n",
    "Retriever_chain = RetrievalQA.from_chain_type(llm,\n",
    "                                       retriever=vectordb.as_retriever(),\n",
    "                                       return_source_documents=True,\n",
    "                                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92170267",
   "metadata": {
    "id": "92170267",
    "outputId": "b4011b44-79ba-4467-eb05-9b230fe4b2ae"
   },
   "outputs": [],
   "source": [
    "# Function to handle chatbot queries\n",
    "def chatbot_response(message, history):\n",
    "    \"\"\"\n",
    "    Function to process user queries and return responses from the HR chatbot\n",
    "    \"\"\"\n",
    "    if message.strip() == \"\":\n",
    "        return \"Please enter a valid question about Nestle's HR policies.\"\n",
    "    \n",
    "    try:\n",
    "        # Get the answer from the chain\n",
    "        start = time.time()\n",
    "        res = Retriever_chain(message)\n",
    "        end = time.time()\n",
    "        \n",
    "        # Format the response\n",
    "        response = res['result']\n",
    "        processing_time = f\"\\n\\n‚è±Ô∏è *Response generated in {round(end - start, 2)} seconds*\"\n",
    "        \n",
    "        return response + processing_time\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Sorry, I encountered an error while processing your question: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf0d866-e8aa-4820-ac78-42c48c440dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom CSS for styling\n",
    "custom_css = \"\"\"\n",
    "#title {\n",
    "    text-align: center;\n",
    "    background: linear-gradient(45deg, #FF6B6B, #4ECDC4);\n",
    "    -webkit-background-clip: text;\n",
    "    -webkit-text-fill-color: transparent;\n",
    "    font-size: 2.5em;\n",
    "    font-weight: bold;\n",
    "    margin-bottom: 20px;\n",
    "}\n",
    "\n",
    "#description {\n",
    "    text-align: center;\n",
    "    font-size: 1.2em;\n",
    "    color: #666;\n",
    "    margin-bottom: 30px;\n",
    "}\n",
    "\n",
    ".gradio-container {\n",
    "    max-width: 800px;\n",
    "    margin: 0 auto;\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "893d8501-26a6-44b4-8048-dbcf48a7b389",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225/2022210204.py:14: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(\n",
      "/tmp/ipykernel_225/2022210204.py:14: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
      "  chatbot = gr.Chatbot(\n"
     ]
    }
   ],
   "source": [
    "# Create Gradio interface\n",
    "with gr.Blocks(css=custom_css, title=\"Nestle HR Assistant\") as demo:\n",
    "    \n",
    "    # Title and description\n",
    "    gr.HTML(\"\"\"\n",
    "        <div id=\"title\">üè¢ Nestle HR Policy Assistant</div>\n",
    "        <div id=\"description\">\n",
    "            Ask me anything about Nestle's HR policies and procedures. \n",
    "            I'm here to help you find the information you need quickly and accurately.\n",
    "        </div>\n",
    "    \"\"\")\n",
    "    \n",
    "    # Create chatbot interface\n",
    "    chatbot = gr.Chatbot(\n",
    "        value=[],\n",
    "        height=400,\n",
    "        bubble_full_width=False,\n",
    "        show_label=False,\n",
    "        container=True\n",
    "    )\n",
    "    \n",
    "    # Create message input\n",
    "    msg = gr.Textbox(\n",
    "        placeholder=\"Ask me about Nestle's HR policies (e.g., 'What is the leave policy?', 'How do I apply for maternity leave?')\",\n",
    "        show_label=False,\n",
    "        max_lines=3,\n",
    "        container=False\n",
    "    )\n",
    "    \n",
    "    # Create buttons\n",
    "    with gr.Row():\n",
    "        submit_btn = gr.Button(\"Send üì§\", variant=\"primary\", scale=1)\n",
    "        clear_btn = gr.Button(\"Clear Chat üóëÔ∏è\", scale=1)\n",
    "    \n",
    "    # Example questions\n",
    "    gr.Examples(\n",
    "        examples=[\n",
    "            [\"What is Nestle's vacation policy?\"],\n",
    "            [\"How do I request time off?\"],\n",
    "            [\"What are the working hours?\"],\n",
    "            [\"Tell me about employee benefits\"],\n",
    "            [\"What is the dress code policy?\"],\n",
    "            [\"How do I report workplace issues?\"]\n",
    "        ],\n",
    "        inputs=msg,\n",
    "        label=\"üí° Try these example questions:\"\n",
    "    )\n",
    "    \n",
    "    # Function to handle user input\n",
    "    def user_input(message, history):\n",
    "        return \"\", history + [[message, None]]\n",
    "    \n",
    "    def bot_response(history):\n",
    "        user_message = history[-1][0]\n",
    "        bot_message = chatbot_response(user_message, history)\n",
    "        history[-1][1] = bot_message\n",
    "        return history\n",
    "    \n",
    "    # Set up event handlers\n",
    "    msg.submit(user_input, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot_response, chatbot, chatbot\n",
    "    )\n",
    "    \n",
    "    submit_btn.click(user_input, [msg, chatbot], [msg, chatbot], queue=False).then(\n",
    "        bot_response, chatbot, chatbot\n",
    "    )\n",
    "    \n",
    "    clear_btn.click(lambda: ([], \"\"), outputs=[chatbot, msg])\n",
    "    \n",
    "    # Footer\n",
    "    gr.HTML(\"\"\"\n",
    "        <div style=\"text-align: center; margin-top: 20px; color: #888; font-size: 0.9em;\">\n",
    "            <p>ü§ñ Powered by OpenAI GPT-3.5 Turbo & LangChain | Built with ‚ù§Ô∏è using Gradio for AGS Advances Generative AI: Building Applications</p>\n",
    "            <p>üìã This assistant is trained on Nestle's HR Policy Document (2012)</p>\n",
    "        </div>\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80261821-0e43-4208-a8cd-7b6bdde19f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://0.0.0.0:7860\n",
      "* Running on public URL: https://d2e929e1611e806ab8.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://d2e929e1611e806ab8.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_225/3825980550.py:12: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  res = Retriever_chain(message)\n"
     ]
    }
   ],
   "source": [
    "# Launch the interface\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch(\n",
    "        share=True,          # Creates a public link\n",
    "        debug=True,          # Enable debug mode\n",
    "        show_error=True,     # Show errors in the interface\n",
    "        server_name=\"0.0.0.0\",  # Allow external access\n",
    "        server_port=7860     # Default Gradio port\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1424e6f-b5d6-46a2-b72c-21a02e27043c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
